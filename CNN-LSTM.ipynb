{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6c14cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c59c2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cc503f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout,Flatten,Conv1D,MaxPooling1D,BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ac6cfcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>digit_1</th>\n",
       "      <th>digit_2</th>\n",
       "      <th>digit_3</th>\n",
       "      <th>Full Text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>95.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>카센터에서 자동차부분정비 타이어오일교환</td>\n",
       "      <td>카 센터 자동차 부분 정비 타이어 오일 교환</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G</td>\n",
       "      <td>47.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>상점내에서 일반인을 대상으로 채소 과일판매</td>\n",
       "      <td>상점 내 일반인 대상 채소 과일 판매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G</td>\n",
       "      <td>46.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>절단하여사업체에도매 공업용고무를가지고 합성고무도매</td>\n",
       "      <td>절단 하여사 업체 에도 매 공업 용 고무 가지 고 합성 고무 도매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G</td>\n",
       "      <td>47.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>영업점에서 일반소비자에게 열쇠잠금장치</td>\n",
       "      <td>영업 점 일 반 소비자 열쇠 잠금장치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q</td>\n",
       "      <td>87.0</td>\n",
       "      <td>872.0</td>\n",
       "      <td>어린이집 보호자의 위탁을 받아 취학전아동보육</td>\n",
       "      <td>어린이집 보호자 위탁 받아 취학 전 아동 보육</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  digit_1  digit_2  digit_3                    Full Text  \\\n",
       "0       S     95.0    952.0        카센터에서 자동차부분정비 타이어오일교환   \n",
       "1       G     47.0    472.0      상점내에서 일반인을 대상으로 채소 과일판매   \n",
       "2       G     46.0    467.0  절단하여사업체에도매 공업용고무를가지고 합성고무도매   \n",
       "3       G     47.0    475.0         영업점에서 일반소비자에게 열쇠잠금장치   \n",
       "4       Q     87.0    872.0     어린이집 보호자의 위탁을 받아 취학전아동보육   \n",
       "\n",
       "                             clean_text  \n",
       "0              카 센터 자동차 부분 정비 타이어 오일 교환  \n",
       "1                  상점 내 일반인 대상 채소 과일 판매  \n",
       "2  절단 하여사 업체 에도 매 공업 용 고무 가지 고 합성 고무 도매  \n",
       "3                  영업 점 일 반 소비자 열쇠 잠금장치  \n",
       "4             어린이집 보호자 위탁 받아 취학 전 아동 보육  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('최종 전처리.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe6a41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>digit_1</th>\n",
       "      <th>digit_2</th>\n",
       "      <th>digit_3</th>\n",
       "      <th>Full Text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>95.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>카센터에서 자동차부분정비 타이어오일교환</td>\n",
       "      <td>카 센터 자동차 부분 정비 타이어 오일 교환</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G</td>\n",
       "      <td>47.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>상점내에서 일반인을 대상으로 채소 과일판매</td>\n",
       "      <td>상점 내 일반인 대상 채소 과일 판매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G</td>\n",
       "      <td>46.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>절단하여사업체에도매 공업용고무를가지고 합성고무도매</td>\n",
       "      <td>절단 하여사 업체 에도 매 공업 용 고무 가지 고 합성 고무 도매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G</td>\n",
       "      <td>47.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>영업점에서 일반소비자에게 열쇠잠금장치</td>\n",
       "      <td>영업 점 일 반 소비자 열쇠 잠금장치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q</td>\n",
       "      <td>87.0</td>\n",
       "      <td>872.0</td>\n",
       "      <td>어린이집 보호자의 위탁을 받아 취학전아동보육</td>\n",
       "      <td>어린이집 보호자 위탁 받아 취학 전 아동 보육</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  digit_1  digit_2  digit_3                    Full Text  \\\n",
       "0       S     95.0    952.0        카센터에서 자동차부분정비 타이어오일교환   \n",
       "1       G     47.0    472.0      상점내에서 일반인을 대상으로 채소 과일판매   \n",
       "2       G     46.0    467.0  절단하여사업체에도매 공업용고무를가지고 합성고무도매   \n",
       "3       G     47.0    475.0         영업점에서 일반소비자에게 열쇠잠금장치   \n",
       "4       Q     87.0    872.0     어린이집 보호자의 위탁을 받아 취학전아동보육   \n",
       "\n",
       "                             clean_text  \n",
       "0              카 센터 자동차 부분 정비 타이어 오일 교환  \n",
       "1                  상점 내 일반인 대상 채소 과일 판매  \n",
       "2  절단 하여사 업체 에도 매 공업 용 고무 가지 고 합성 고무 도매  \n",
       "3                  영업 점 일 반 소비자 열쇠 잠금장치  \n",
       "4             어린이집 보호자 위탁 받아 취학 전 아동 보육  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df[:1000000]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72d9965b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder1 = LabelEncoder()\n",
    "train['digit_1'] = encoder1.fit_transform(train['digit_1'])\n",
    "train['digit_1'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a3a3926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder2 = LabelEncoder()\n",
    "train['digit_2'] = encoder2.fit_transform(train['digit_2'])\n",
    "train['digit_2'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "937cd66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder3 = LabelEncoder()\n",
    "train['digit_3'] = encoder3.fit_transform(train['digit_3'])\n",
    "train['digit_3'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a4de6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = np.load('text.npy') # Sentence-Piece Tokenizer 전처리 완료한 데이터 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c962a885",
   "metadata": {},
   "source": [
    "# 전처리 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e327888a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  633, 1943, 3832],\n",
       "       [   0,    0,    0, ...,  296,  147,   12],\n",
       "       [   0,    0,    0, ..., 1304,  608,   23],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 1444, 1030,   12],\n",
       "       [   0,    0,    0, ..., 1434, 1725,   49],\n",
       "       [   0,    0,    0, ...,   44, 1310,  203]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 21\n",
    "\n",
    "text = tf.keras.preprocessing.sequence.pad_sequences(text, maxlen=max_len)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0863303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = text[:1000000]\n",
    "test_data = text[1000000:]\n",
    "target = train['digit_1']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, target, test_size=0.2, shuffle=True, stratify=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8393f5a4",
   "metadata": {},
   "source": [
    "### CNN - LSTM (digit1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "211778ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10760\n",
    "embedding_dim = 128\n",
    "hidden_units = 128\n",
    "num_classes = 19 # 대분류 19개 카테고리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ebfe3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "# Convolutional Layer1\n",
    "model1.add(Embedding(vocab_size, embedding_dim,input_length= max_len))\n",
    "model1.add(Conv1D(filters=32, kernel_size=2, activation='relu',padding='valid',strides=1))\n",
    "model1.add(MaxPooling1D(pool_size=2))\n",
    "model1.add(BatchNormalization())\n",
    "\n",
    "# LSTM Layer \n",
    "model1.add(LSTM(hidden_units, return_sequences=True,activation='tanh'))\n",
    "model1.add(LSTM(hidden_units, return_sequences=True,activation='tanh'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25bf9551",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 21, 128)           1377280   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 20, 32)            8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 10, 32)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 10, 32)            128       \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 10, 128)           82432     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10, 128)           131584    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 19)                24339     \n",
      "=================================================================\n",
      "Total params: 1,623,987\n",
      "Trainable params: 1,623,923\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0788822",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode = \"auto\", verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model1.h5', monitor='val_loss', mode = \"auto\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e889d33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 748s 37ms/step - loss: 0.1722 - accuracy: 0.9553 - val_loss: 0.1154 - val_accuracy: 0.9689\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11536, saving model to best_model1.h5\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 820s 41ms/step - loss: 0.1119 - accuracy: 0.9704 - val_loss: 0.1042 - val_accuracy: 0.9716\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11536 to 0.10419, saving model to best_model1.h5\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 861s 43ms/step - loss: 0.0964 - accuracy: 0.9743 - val_loss: 0.1028 - val_accuracy: 0.9726\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.10419 to 0.10277, saving model to best_model1.h5\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 863s 43ms/step - loss: 0.0862 - accuracy: 0.9766 - val_loss: 0.0995 - val_accuracy: 0.9731\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.10277 to 0.09953, saving model to best_model1.h5\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 925s 46ms/step - loss: 0.0785 - accuracy: 0.9786 - val_loss: 0.1048 - val_accuracy: 0.9728\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.09953\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model1.fit(X_train, y_train, batch_size=32, epochs=5, callbacks=[es, mc], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48f25875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 [==============================] - 70s 11ms/step - loss: 0.1005 - accuracy: 0.9732\n",
      "테스트 정확도: 0.9732\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 정확도: %.4f\" % (model1.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8702188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.9546719e-08, 4.6803317e-09, 1.9415420e-05, ..., 2.3403267e-08,\n",
       "        5.2224351e-08, 4.2582610e-07],\n",
       "       [1.1820782e-10, 2.3775701e-10, 3.0921835e-06, ..., 1.4734679e-10,\n",
       "        2.3098746e-08, 1.7536028e-09],\n",
       "       [1.1707170e-09, 9.9615527e-10, 3.7998993e-06, ..., 3.7487107e-09,\n",
       "        5.8047152e-07, 4.8575082e-08],\n",
       "       ...,\n",
       "       [1.7905883e-11, 3.9168720e-11, 4.5640851e-09, ..., 2.2388877e-10,\n",
       "        2.0952044e-10, 3.0624112e-09],\n",
       "       [4.6483842e-10, 1.7043931e-09, 4.5281186e-07, ..., 2.1544286e-06,\n",
       "        3.4170162e-07, 9.9998760e-01],\n",
       "       [4.8403018e-03, 1.1898049e-03, 6.7741022e-02, ..., 8.3854934e-03,\n",
       "        3.4097157e-02, 1.6319806e-02]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1 = model1.predict(X_test)\n",
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b95612d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  8,  8, ...,  7, 18, 15], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict1 = []\n",
    "for i in range(pred1.shape[0]):\n",
    "    predict1.append(pred1[i].argmax())\n",
    "predict1 = np.array(predict1)\n",
    "predict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42cef86c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76       213\n",
      "           1       0.87      0.79      0.83        85\n",
      "           2       0.95      0.96      0.96     21038\n",
      "           3       0.94      0.87      0.91       151\n",
      "           4       0.90      0.84      0.87       451\n",
      "           5       0.95      0.94      0.94      7010\n",
      "           6       0.98      0.98      0.98     49294\n",
      "           7       0.99      0.99      0.99     19608\n",
      "           8       0.99      0.99      0.99     37485\n",
      "           9       0.91      0.93      0.92      2172\n",
      "          10       0.98      0.97      0.98      2076\n",
      "          11       0.99      0.98      0.98      8028\n",
      "          12       0.94      0.93      0.93      5687\n",
      "          13       0.85      0.89      0.87      3540\n",
      "          14       0.88      0.93      0.91       593\n",
      "          15       0.98      0.97      0.97      9322\n",
      "          16       0.97      0.98      0.97      7218\n",
      "          17       0.96      0.96      0.96      5950\n",
      "          18       0.98      0.97      0.98     20079\n",
      "\n",
      "    accuracy                           0.97    200000\n",
      "   macro avg       0.94      0.93      0.93    200000\n",
      "weighted avg       0.97      0.97      0.97    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ('Here is the classification report:')\n",
    "print (classification_report(y_test, predict1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ae65f4",
   "metadata": {},
   "source": [
    "### 모델개발용 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d318894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.03244632e-11, 3.20108141e-11, 5.13272835e-06, ...,\n",
       "        1.10988732e-10, 5.43994751e-08, 2.35793829e-09],\n",
       "       [2.91725513e-07, 1.15970185e-08, 3.39414203e-03, ...,\n",
       "        9.23644961e-07, 9.14432519e-07, 3.31375259e-06],\n",
       "       [6.03968786e-08, 2.15418243e-08, 7.81658237e-05, ...,\n",
       "        2.76987284e-05, 4.00899626e-05, 9.99415874e-01],\n",
       "       ...,\n",
       "       [9.56981457e-05, 1.45059421e-05, 1.57141674e-03, ...,\n",
       "        3.65797132e-05, 2.61703157e-04, 2.36944208e-04],\n",
       "       [3.18315233e-06, 8.25528730e-08, 3.41778991e-06, ...,\n",
       "        3.69546673e-04, 9.88729537e-01, 3.63292085e-04],\n",
       "       [9.51939946e-05, 3.09158131e-05, 1.09350694e-04, ...,\n",
       "        2.55075167e-04, 5.51725563e-04, 2.53769546e-03]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit1_pred = model1.predict(test_data)\n",
    "digit1_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07fe8cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  6, 18, ...,  6, 17, 11], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit1_predict = []\n",
    "for i in range(digit1_pred.shape[0]):\n",
    "    digit1_predict.append(digit1_pred[i].argmax())\n",
    "digit1_predict = np.array(digit1_predict)\n",
    "digit1_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b88cf75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I', 'G', 'S', ..., 'G', 'R', 'L'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit1_predict = encoder1.inverse_transform(digit1_predict)\n",
    "digit1_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdcbdfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digit1_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce5dabf",
   "metadata": {},
   "source": [
    "### CNN - LSTM (digit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cd5161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target2 = train['digit_2']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, target2, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd89c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10760\n",
    "embedding_dim = 128\n",
    "hidden_units = 128\n",
    "num_classes = 74 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b9f02f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "# Convolutional Layer1\n",
    "model2.add(Embedding(vocab_size, embedding_dim,input_length= max_len))\n",
    "model2.add(Conv1D(filters=32, kernel_size=2, activation='relu',padding='valid',strides=1))\n",
    "model2.add(MaxPooling1D(pool_size=2))\n",
    "model2.add(BatchNormalization())\n",
    "\n",
    "# LSTM Layer \n",
    "model2.add(LSTM(hidden_units, return_sequences=True,activation='tanh'))\n",
    "model2.add(LSTM(hidden_units, return_sequences=True,activation='tanh'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ce5fdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 21, 128)           1377280   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 20, 32)            8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 10, 32)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 10, 32)            128       \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 10, 128)           82432     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 10, 128)           131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 74)                94794     \n",
      "=================================================================\n",
      "Total params: 1,694,442\n",
      "Trainable params: 1,694,378\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0d4da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc2 = ModelCheckpoint('best_model2.h5', monitor='val_loss', mode = \"auto\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e4aaed3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 969s 48ms/step - loss: 0.4029 - accuracy: 0.8970 - val_loss: 0.2729 - val_accuracy: 0.9263\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.27289, saving model to best_model2.h5\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 838s 42ms/step - loss: 0.2739 - accuracy: 0.9279 - val_loss: 0.2479 - val_accuracy: 0.9328\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.27289 to 0.24793, saving model to best_model2.h5\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 1015s 51ms/step - loss: 0.2434 - accuracy: 0.9345 - val_loss: 0.2386 - val_accuracy: 0.9355\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.24793 to 0.23863, saving model to best_model2.h5\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 1008s 50ms/step - loss: 0.2240 - accuracy: 0.9393 - val_loss: 0.2368 - val_accuracy: 0.9362\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.23863 to 0.23683, saving model to best_model2.h5\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 836s 42ms/step - loss: 0.2089 - accuracy: 0.9430 - val_loss: 0.2350 - val_accuracy: 0.9369\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.23683 to 0.23502, saving model to best_model2.h5\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history2 = model2.fit(X_train, y_train, batch_size=32, epochs=5, callbacks=[es, mc2], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd7cba81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 [==============================] - 64s 10ms/step - loss: 0.2300 - accuracy: 0.9376\n",
      "테스트 정확도: 0.9376\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 정확도: %.4f\" % (model2.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8709b266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.45849502e-07, 1.04273061e-08, 1.86578518e-07, ...,\n",
       "        1.36696315e-07, 2.61645056e-07, 7.02760374e-08],\n",
       "       [7.17393050e-05, 2.41151383e-06, 7.69458438e-06, ...,\n",
       "        9.97355019e-05, 1.42155832e-03, 3.26807203e-04],\n",
       "       [3.32512108e-11, 9.63055261e-11, 2.42635144e-12, ...,\n",
       "        2.14673985e-08, 1.81168858e-08, 9.99996424e-01],\n",
       "       ...,\n",
       "       [2.56060389e-06, 3.58855190e-09, 1.10603565e-07, ...,\n",
       "        7.79994707e-07, 3.01738346e-05, 2.60156885e-05],\n",
       "       [5.38527775e-06, 2.10963194e-07, 2.79878295e-05, ...,\n",
       "        1.30842159e-06, 1.64081300e-07, 4.36250775e-06],\n",
       "       [4.96126418e-10, 2.32369141e-11, 2.14486172e-11, ...,\n",
       "        5.25102280e-07, 6.64239367e-12, 1.47263568e-09]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model2.predict(X_test)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "099e6ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40, 41, 73, ..., 41, 47, 57], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict2 = []\n",
    "for i in range(pred2.shape[0]):\n",
    "    predict2.append(pred2[i].argmax())\n",
    "predict2 = np.array(predict2)\n",
    "predict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40b4a2f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.55      0.64       159\n",
      "           1       0.82      0.48      0.61        29\n",
      "           2       1.00      0.57      0.73        28\n",
      "           5       0.88      0.70      0.78        83\n",
      "           7       0.88      0.93      0.90      2945\n",
      "           8       1.00      0.23      0.38        60\n",
      "          10       0.88      0.78      0.83      1060\n",
      "          11       0.91      0.90      0.91      1142\n",
      "          12       0.85      0.79      0.82       258\n",
      "          13       0.78      0.67      0.72       342\n",
      "          14       0.84      0.80      0.82       332\n",
      "          15       0.87      0.89      0.88       818\n",
      "          16       0.00      0.00      0.00        11\n",
      "          17       0.64      0.69      0.66       651\n",
      "          18       0.56      0.07      0.12        72\n",
      "          19       0.70      0.78      0.74      1198\n",
      "          20       0.79      0.80      0.80       588\n",
      "          21       0.60      0.38      0.46       461\n",
      "          22       0.74      0.74      0.74      3424\n",
      "          23       0.63      0.64      0.63       664\n",
      "          24       0.72      0.52      0.61       683\n",
      "          25       0.68      0.70      0.69      1092\n",
      "          26       0.61      0.74      0.67      2412\n",
      "          27       0.55      0.41      0.47       571\n",
      "          28       0.82      0.43      0.57       219\n",
      "          29       0.80      0.84      0.82       616\n",
      "          30       0.74      0.72      0.73       937\n",
      "          31       0.82      0.86      0.84       680\n",
      "          32       0.93      0.89      0.91       151\n",
      "          33       1.00      0.72      0.84        32\n",
      "          34       0.77      0.85      0.81        81\n",
      "          35       0.91      0.82      0.86       301\n",
      "          36       0.00      0.00      0.00         4\n",
      "          37       0.82      0.85      0.83      1349\n",
      "          38       0.91      0.91      0.91      5582\n",
      "          39       0.95      0.91      0.93      1513\n",
      "          40       0.93      0.91      0.92     15365\n",
      "          41       0.94      0.97      0.96     32341\n",
      "          42       0.99      0.99      0.99     18059\n",
      "          43       0.90      0.56      0.69        66\n",
      "          44       0.00      0.00      0.00         3\n",
      "          45       0.93      0.91      0.92      1506\n",
      "          46       0.99      0.99      0.99      2805\n",
      "          47       0.99      0.99      0.99     34614\n",
      "          48       0.85      0.92      0.88      1077\n",
      "          49       0.83      0.83      0.83       285\n",
      "          50       0.77      0.70      0.73        33\n",
      "          51       0.91      0.88      0.89       217\n",
      "          52       0.83      0.61      0.70       388\n",
      "          53       0.84      0.69      0.75       170\n",
      "          54       0.98      0.89      0.94      1029\n",
      "          55       0.92      0.88      0.90       382\n",
      "          56       0.82      0.92      0.86       640\n",
      "          57       0.99      0.98      0.98      8074\n",
      "          58       0.85      0.87      0.86       395\n",
      "          59       0.92      0.92      0.92      2774\n",
      "          60       0.94      0.92      0.93      1433\n",
      "          61       0.93      0.89      0.91      1106\n",
      "          62       0.88      0.83      0.85       559\n",
      "          63       0.86      0.89      0.87      2057\n",
      "          64       0.88      0.86      0.87       902\n",
      "          65       0.90      0.88      0.89       594\n",
      "          66       0.97      0.98      0.97      9342\n",
      "          67       0.99      0.96      0.98      3593\n",
      "          68       0.95      0.95      0.95      3557\n",
      "          69       0.93      0.83      0.88       875\n",
      "          70       0.97      0.96      0.96      5074\n",
      "          71       0.94      0.96      0.95      4749\n",
      "          72       0.96      0.95      0.95      4058\n",
      "          73       0.99      0.99      0.99     11330\n",
      "\n",
      "    accuracy                           0.94    200000\n",
      "   macro avg       0.82      0.75      0.78    200000\n",
      "weighted avg       0.94      0.94      0.94    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ('Here is the classification report:')\n",
    "print (classification_report(y_test, predict2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81f277a",
   "metadata": {},
   "source": [
    "### 모델개발용 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f2da332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4500429e-10, 2.0278322e-11, 1.6345071e-08, ..., 6.5445240e-11,\n",
       "        6.4859663e-12, 9.7628194e-10],\n",
       "       [8.3109808e-05, 2.2012517e-07, 2.1425194e-06, ..., 5.2826297e-05,\n",
       "        2.8792188e-05, 5.2629483e-05],\n",
       "       [1.6163108e-06, 1.1555074e-08, 2.7449646e-08, ..., 9.9993038e-01,\n",
       "        6.5426564e-10, 1.8014912e-07],\n",
       "       ...,\n",
       "       [5.3636136e-06, 9.8136965e-08, 1.1713762e-06, ..., 3.8461239e-06,\n",
       "        5.2268613e-05, 2.0972757e-05],\n",
       "       [2.2151289e-06, 7.4453618e-07, 3.1578804e-06, ..., 1.6305519e-03,\n",
       "        6.9220177e-06, 1.8463249e-04],\n",
       "       [8.2490951e-06, 1.2492598e-06, 1.1992653e-06, ..., 3.4571681e-04,\n",
       "        2.9781427e-06, 3.2825134e-05]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit2_pred = model2.predict(test_data)\n",
    "digit2_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4351a6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47, 40, 71, ..., 41, 69, 57], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit2_predict = []\n",
    "for i in range(digit2_pred.shape[0]):\n",
    "    digit2_predict.append(digit2_pred[i].argmax())\n",
    "digit2_predict = np.array(digit2_predict)\n",
    "digit2_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83ae0716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56., 46., 94., ..., 47., 90., 68.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit2_predict = encoder2.inverse_transform(digit2_predict)\n",
    "digit2_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea745d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digit2_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d634a85",
   "metadata": {},
   "source": [
    "### CNN - LSTM (digit3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29b6cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "target3 = train['digit_3']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, target3, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7aa096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10760\n",
    "embedding_dim = 128\n",
    "hidden_units = 128\n",
    "num_classes = 225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c491ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "# Convolutional Layer1\n",
    "model3.add(Embedding(vocab_size, embedding_dim,input_length= max_len))\n",
    "model3.add(Conv1D(filters=32, kernel_size=2, activation='relu',padding='valid',strides=1))\n",
    "model3.add(MaxPooling1D(pool_size=2))\n",
    "model3.add(BatchNormalization())\n",
    "\n",
    "# LSTM Layer \n",
    "model3.add(LSTM(hidden_units, return_sequences=True,activation='tanh'))\n",
    "model3.add(LSTM(hidden_units, return_sequences=True,activation='tanh'))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a30e36e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc3 = ModelCheckpoint('best_model3.h5', monitor='val_loss', mode = \"auto\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d1a8d60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 1714s 85ms/step - loss: 0.6789 - accuracy: 0.8393 - val_loss: 0.4430 - val_accuracy: 0.8903\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44303, saving model to best_model3.h5\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 1458s 73ms/step - loss: 0.4562 - accuracy: 0.8882 - val_loss: 0.3954 - val_accuracy: 0.9003\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.44303 to 0.39536, saving model to best_model3.h5\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 1462s 73ms/step - loss: 0.4082 - accuracy: 0.8984 - val_loss: 0.3803 - val_accuracy: 0.9028\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.39536 to 0.38026, saving model to best_model3.h5\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 1483s 74ms/step - loss: 0.3790 - accuracy: 0.9048 - val_loss: 0.3706 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.38026 to 0.37058, saving model to best_model3.h5\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 1540s 77ms/step - loss: 0.3580 - accuracy: 0.9095 - val_loss: 0.3667 - val_accuracy: 0.9068\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.37058 to 0.36674, saving model to best_model3.h5\n"
     ]
    }
   ],
   "source": [
    "model3.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history3 = model3.fit(X_train, y_train, batch_size=32, epochs=5, callbacks=[es, mc3], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da5a068d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 [==============================] - 440s 24ms/step - loss: 0.3685 - accuracy: 0.9071\n",
      "테스트 정확도: 0.9071\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 정확도: %.4f\" % (model3.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e079f63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1774032e-10, 1.5438582e-10, 2.2651525e-11, ..., 1.7291192e-09,\n",
       "        1.3650728e-09, 7.1947248e-08],\n",
       "       [3.2516841e-08, 5.0423692e-09, 5.7901400e-10, ..., 2.5989505e-07,\n",
       "        9.7591374e-07, 3.0793447e-07],\n",
       "       [1.1112172e-09, 8.7802174e-09, 2.4129050e-09, ..., 1.6536006e-09,\n",
       "        1.7339855e-07, 5.4877808e-07],\n",
       "       ...,\n",
       "       [2.1244948e-06, 1.6433320e-06, 2.1831215e-06, ..., 1.3676956e-06,\n",
       "        4.8580878e-05, 1.7833547e-05],\n",
       "       [3.6728711e-08, 5.0499311e-09, 1.0734736e-08, ..., 9.0353608e-10,\n",
       "        4.9443849e-09, 2.5050818e-08],\n",
       "       [4.8379728e-10, 1.4503644e-09, 5.8748645e-10, ..., 9.5291677e-11,\n",
       "        3.0911245e-08, 6.1527072e-10]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model3.predict(X_test)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1077f699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([135, 132, 148, ..., 147,  18, 147], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict3 = []\n",
    "for i in range(pred3.shape[0]):\n",
    "    predict3.append(pred3[i].argmax())\n",
    "predict3 = np.array(predict3)\n",
    "predict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "85acfef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.70      0.75        80\n",
      "           1       0.83      0.80      0.81        44\n",
      "           2       0.67      0.13      0.22        31\n",
      "           3       0.81      0.72      0.76        18\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.94      0.56      0.70        27\n",
      "           9       0.74      0.51      0.61        39\n",
      "          10       1.00      0.81      0.90        43\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.79      0.57      0.66       138\n",
      "          13       0.86      0.81      0.83       185\n",
      "          14       0.73      0.57      0.64       221\n",
      "          15       0.95      0.79      0.86       149\n",
      "          16       0.00      0.00      0.00        13\n",
      "          17       0.82      0.78      0.80       259\n",
      "          18       0.82      0.90      0.86      1888\n",
      "          19       0.79      0.75      0.77        64\n",
      "          20       0.86      0.53      0.65        34\n",
      "          21       0.00      0.00      0.00        29\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.89      0.66      0.76        83\n",
      "          24       0.70      0.83      0.76       543\n",
      "          25       0.83      0.27      0.41        37\n",
      "          26       0.78      0.73      0.75       188\n",
      "          27       0.59      0.40      0.48       166\n",
      "          28       0.91      0.88      0.89       916\n",
      "          29       0.57      0.57      0.57         7\n",
      "          30       0.74      0.57      0.65        40\n",
      "          31       0.88      0.57      0.69       150\n",
      "          32       0.78      0.76      0.77       175\n",
      "          33       0.73      0.72      0.73        96\n",
      "          34       0.56      0.55      0.55        60\n",
      "          35       0.69      0.63      0.66       279\n",
      "          36       0.00      0.00      0.00         5\n",
      "          37       0.00      0.00      0.00        41\n",
      "          38       0.80      0.77      0.78       231\n",
      "          39       0.63      0.52      0.57       109\n",
      "          40       0.85      0.91      0.88       805\n",
      "          41       0.00      0.00      0.00         9\n",
      "          42       0.00      0.00      0.00         4\n",
      "          43       0.00      0.00      0.00        12\n",
      "          44       0.41      0.10      0.16        72\n",
      "          45       0.67      0.34      0.45       154\n",
      "          46       0.76      0.66      0.70        67\n",
      "          47       0.61      0.58      0.60       349\n",
      "          48       0.00      0.00      0.00        18\n",
      "          49       0.00      0.00      0.00         3\n",
      "          50       0.60      0.08      0.14        39\n",
      "          51       0.00      0.00      0.00        29\n",
      "          52       0.71      0.67      0.69       162\n",
      "          53       0.60      0.81      0.69       981\n",
      "          54       0.80      0.68      0.73       114\n",
      "          55       0.76      0.76      0.76       118\n",
      "          56       0.78      0.87      0.82       150\n",
      "          57       0.81      0.74      0.77       179\n",
      "          58       0.56      0.29      0.38       252\n",
      "          59       0.49      0.26      0.34        93\n",
      "          60       0.74      0.36      0.48        70\n",
      "          61       0.71      0.68      0.70       831\n",
      "          62       0.00      0.00      0.00         6\n",
      "          63       0.57      0.82      0.67      2478\n",
      "          64       0.50      0.29      0.37        76\n",
      "          65       0.47      0.64      0.54       349\n",
      "          66       0.82      0.24      0.37        75\n",
      "          67       0.61      0.43      0.50       143\n",
      "          68       0.57      0.11      0.18        38\n",
      "          70       0.85      0.70      0.77       303\n",
      "          71       0.54      0.38      0.44       296\n",
      "          72       0.71      0.46      0.56        37\n",
      "          73       0.00      0.00      0.00         5\n",
      "          74       0.70      0.73      0.72       539\n",
      "          75       0.00      0.00      0.00        19\n",
      "          76       0.64      0.59      0.62        74\n",
      "          77       0.71      0.73      0.72       249\n",
      "          78       0.45      0.25      0.32       107\n",
      "          79       0.00      0.00      0.00        77\n",
      "          80       0.52      0.63      0.57       979\n",
      "          81       0.63      0.52      0.57      1402\n",
      "          82       0.00      0.00      0.00         5\n",
      "          83       0.96      0.32      0.49        77\n",
      "          84       0.52      0.18      0.26       511\n",
      "          85       0.00      0.00      0.00         5\n",
      "          86       0.84      0.46      0.60       157\n",
      "          87       0.00      0.00      0.00        20\n",
      "          88       0.67      0.09      0.16        22\n",
      "          89       0.00      0.00      0.00        24\n",
      "          90       0.86      0.81      0.83       678\n",
      "          91       0.85      0.69      0.76       117\n",
      "          92       0.00      0.00      0.00        15\n",
      "          93       0.43      0.33      0.37        58\n",
      "          94       0.47      0.24      0.32        38\n",
      "          95       0.74      0.73      0.73       705\n",
      "          96       0.87      0.85      0.86       679\n",
      "          97       0.90      0.91      0.91       151\n",
      "          98       1.00      0.38      0.56        13\n",
      "          99       0.00      0.00      0.00         3\n",
      "         100       1.00      0.80      0.89        25\n",
      "         101       0.85      0.80      0.82        84\n",
      "         102       0.86      0.89      0.87       134\n",
      "         103       0.71      0.58      0.64        64\n",
      "         104       0.68      0.70      0.69       115\n",
      "         105       0.00      0.00      0.00         7\n",
      "         106       0.88      0.87      0.87       726\n",
      "         107       0.68      0.72      0.70       708\n",
      "         108       0.86      0.78      0.82       948\n",
      "         109       0.81      0.84      0.82      1157\n",
      "         110       0.92      0.92      0.92       923\n",
      "         111       0.87      0.95      0.90      2282\n",
      "         112       0.78      0.40      0.53       118\n",
      "         113       0.83      0.70      0.76       327\n",
      "         114       0.99      0.96      0.98       469\n",
      "         115       0.91      0.92      0.92       922\n",
      "         116       0.93      0.87      0.90        97\n",
      "         117       0.77      0.70      0.73       473\n",
      "         118       0.87      0.72      0.78       531\n",
      "         119       0.91      0.90      0.91      3653\n",
      "         120       0.84      0.80      0.82      3749\n",
      "         121       0.83      0.84      0.84      2943\n",
      "         122       0.83      0.84      0.84      1573\n",
      "         123       0.83      0.86      0.85      2423\n",
      "         124       0.76      0.59      0.66       132\n",
      "         125       0.95      0.95      0.95      5301\n",
      "         126       0.88      0.90      0.89      5143\n",
      "         127       0.92      0.90      0.91      1894\n",
      "         128       0.94      0.95      0.95      7274\n",
      "         129       0.85      0.86      0.85      2577\n",
      "         130       0.87      0.88      0.87      1467\n",
      "         131       0.97      0.97      0.97       926\n",
      "         132       0.91      0.92      0.91      5985\n",
      "         133       0.88      0.92      0.90      1847\n",
      "         134       0.86      0.46      0.60        13\n",
      "         135       1.00      1.00      1.00      7918\n",
      "         136       0.99      0.99      0.99      9714\n",
      "         137       0.92      0.94      0.93       407\n",
      "         138       0.00      0.00      0.00         2\n",
      "         139       0.77      0.75      0.76        55\n",
      "         140       0.00      0.00      0.00         9\n",
      "         141       0.00      0.00      0.00         5\n",
      "         142       0.00      0.00      0.00         2\n",
      "         143       0.89      0.92      0.90       320\n",
      "         144       0.90      0.91      0.91      1157\n",
      "         145       0.98      0.99      0.99      2478\n",
      "         146       0.94      0.88      0.91       292\n",
      "         147       0.98      0.98      0.98     24530\n",
      "         148       0.97      0.97      0.97      9907\n",
      "         149       0.87      0.85      0.86       326\n",
      "         150       0.85      0.89      0.87       755\n",
      "         151       0.87      0.82      0.85       219\n",
      "         152       0.87      0.54      0.67        37\n",
      "         153       0.00      0.00      0.00         5\n",
      "         154       0.73      0.67      0.70        36\n",
      "         155       0.98      0.96      0.97       168\n",
      "         156       0.77      0.64      0.70        56\n",
      "         157       0.69      0.71      0.70       389\n",
      "         158       0.53      0.46      0.49        92\n",
      "         159       0.62      0.46      0.52        70\n",
      "         160       0.96      0.99      0.98       805\n",
      "         161       0.53      0.80      0.63        25\n",
      "         162       0.79      0.83      0.81       210\n",
      "         163       0.84      0.86      0.85       315\n",
      "         165       0.87      0.53      0.66        38\n",
      "         166       0.88      0.75      0.81       256\n",
      "         167       0.87      0.90      0.88       396\n",
      "         168       0.92      0.92      0.92      1401\n",
      "         169       0.98      0.98      0.98      6654\n",
      "         170       0.73      0.81      0.77       294\n",
      "         171       0.58      0.47      0.52        81\n",
      "         172       0.95      0.98      0.97       804\n",
      "         173       0.98      0.98      0.98       601\n",
      "         174       0.88      0.85      0.87       597\n",
      "         175       0.82      0.54      0.65        26\n",
      "         176       0.81      0.85      0.83       664\n",
      "         177       1.00      0.38      0.55        24\n",
      "         178       0.91      0.90      0.91      1110\n",
      "         179       0.71      0.77      0.74       356\n",
      "         180       0.99      0.97      0.98       207\n",
      "         181       0.87      0.81      0.84       352\n",
      "         182       0.97      0.96      0.96       468\n",
      "         183       0.72      0.63      0.67       113\n",
      "         184       0.69      0.66      0.67       134\n",
      "         185       0.94      0.91      0.93       395\n",
      "         186       0.79      0.33      0.46        46\n",
      "         187       0.93      0.95      0.94       729\n",
      "         188       0.97      0.94      0.96       547\n",
      "         189       0.69      0.70      0.69        97\n",
      "         190       0.70      0.67      0.68       707\n",
      "         191       0.91      0.86      0.88       204\n",
      "         192       0.81      0.89      0.84       374\n",
      "         193       0.66      0.81      0.73       313\n",
      "         194       0.00      0.00      0.00         9\n",
      "         195       0.94      0.87      0.90       240\n",
      "         196       0.68      0.44      0.54        86\n",
      "         198       0.99      0.88      0.93       250\n",
      "         199       0.00      0.00      0.00         6\n",
      "         200       0.98      0.99      0.98       690\n",
      "         201       0.97      0.95      0.96       271\n",
      "         202       0.90      0.94      0.92        77\n",
      "         203       0.25      0.09      0.13        11\n",
      "         204       0.89      0.95      0.92      3489\n",
      "         205       0.92      0.87      0.89      4696\n",
      "         206       0.66      0.60      0.63       184\n",
      "         207       0.84      0.79      0.81       187\n",
      "         208       0.99      0.98      0.98      3041\n",
      "         209       0.98      0.98      0.98       169\n",
      "         210       0.73      0.64      0.68       234\n",
      "         211       0.94      0.88      0.91       417\n",
      "         212       0.92      0.96      0.94      3180\n",
      "         213       0.76      0.74      0.75       271\n",
      "         214       0.93      0.91      0.92       583\n",
      "         215       0.94      0.96      0.95      1960\n",
      "         216       0.94      0.97      0.96      3031\n",
      "         217       0.65      0.61      0.63       346\n",
      "         218       0.88      0.79      0.83        91\n",
      "         219       0.95      0.94      0.94      4302\n",
      "         220       0.91      0.93      0.92       321\n",
      "         221       0.97      0.98      0.97      2418\n",
      "         222       0.90      0.93      0.92      1376\n",
      "         223       0.99      0.99      0.99      8614\n",
      "         224       0.97      0.97      0.97      2712\n",
      "\n",
      "    accuracy                           0.91    200000\n",
      "   macro avg       0.69      0.62      0.64    200000\n",
      "weighted avg       0.91      0.91      0.90    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ('Here is the classification report:')\n",
    "print (classification_report(y_test, predict3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c974cebe",
   "metadata": {},
   "source": [
    "#### 모델개발용 데이터 예측 (digit_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa6d0143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.28453442e-09, 9.39776257e-09, 4.28662750e-09, ...,\n",
       "        1.31704592e-09, 9.62051772e-08, 7.10673609e-09],\n",
       "       [6.32077857e-08, 5.95717164e-09, 1.11455858e-08, ...,\n",
       "        1.04431751e-06, 3.57007188e-08, 2.20646204e-08],\n",
       "       [1.57847694e-06, 1.36167642e-07, 1.03913443e-07, ...,\n",
       "        5.52972779e-08, 1.75750647e-05, 1.31764546e-05],\n",
       "       ...,\n",
       "       [1.27368639e-05, 2.44962075e-06, 1.21168148e-06, ...,\n",
       "        1.57710947e-05, 5.73136713e-05, 6.29236456e-05],\n",
       "       [3.04460656e-07, 9.52211565e-07, 8.24323979e-06, ...,\n",
       "        1.03302604e-07, 2.26771706e-04, 5.85728503e-06],\n",
       "       [6.26271790e-09, 2.07695479e-08, 1.56772060e-07, ...,\n",
       "        1.79854514e-08, 3.33998105e-06, 1.54950194e-05]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit3_pred = model3.predict(test_data)\n",
    "digit3_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f223ad4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([147, 122, 219, ..., 132, 214, 169], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit3_predict = []\n",
    "for i in range(digit3_pred.shape[0]):\n",
    "    digit3_predict.append(digit3_pred[i].argmax())\n",
    "digit3_predict = np.array(digit3_predict)\n",
    "digit3_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a798fa0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([561., 466., 949., ..., 478., 902., 682.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit3_predict = encoder3.inverse_transform(digit3_predict)\n",
    "digit3_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1cff501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digit3_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4acd7f6",
   "metadata": {},
   "source": [
    "### 답안 작성용 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f252e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('문서분류/답안 작성용 파일.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d6eddcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digit1_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "781e4634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digit2_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5325b937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digit3_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8bae09a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['digit_1'] = digit1_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "22c68c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['digit_2'] = digit2_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "87ebe4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['digit_3'] = digit3_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2da3dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('답안 작성용 파일(CNN-LSTM).csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
