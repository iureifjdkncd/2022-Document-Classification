{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6c14cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c59c2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cc503f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ac6cfcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>digit_1</th>\n",
       "      <th>digit_2</th>\n",
       "      <th>digit_3</th>\n",
       "      <th>Full Text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>95.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>카센터에서 자동차부분정비 타이어오일교환</td>\n",
       "      <td>카 센터 자동차 부분 정비 타이어 오일 교환</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G</td>\n",
       "      <td>47.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>상점내에서 일반인을 대상으로 채소 과일판매</td>\n",
       "      <td>상점 내 일반인 대상 채소 과일 판매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G</td>\n",
       "      <td>46.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>절단하여사업체에도매 공업용고무를가지고 합성고무도매</td>\n",
       "      <td>절단 하여사 업체 에도 매 공업 용 고무 가지 고 합성 고무 도매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G</td>\n",
       "      <td>47.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>영업점에서 일반소비자에게 열쇠잠금장치</td>\n",
       "      <td>영업 점 일 반 소비자 열쇠 잠금장치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q</td>\n",
       "      <td>87.0</td>\n",
       "      <td>872.0</td>\n",
       "      <td>어린이집 보호자의 위탁을 받아 취학전아동보육</td>\n",
       "      <td>어린이집 보호자 위탁 받아 취학 전 아동 보육</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  digit_1  digit_2  digit_3                    Full Text  \\\n",
       "0       S     95.0    952.0        카센터에서 자동차부분정비 타이어오일교환   \n",
       "1       G     47.0    472.0      상점내에서 일반인을 대상으로 채소 과일판매   \n",
       "2       G     46.0    467.0  절단하여사업체에도매 공업용고무를가지고 합성고무도매   \n",
       "3       G     47.0    475.0         영업점에서 일반소비자에게 열쇠잠금장치   \n",
       "4       Q     87.0    872.0     어린이집 보호자의 위탁을 받아 취학전아동보육   \n",
       "\n",
       "                             clean_text  \n",
       "0              카 센터 자동차 부분 정비 타이어 오일 교환  \n",
       "1                  상점 내 일반인 대상 채소 과일 판매  \n",
       "2  절단 하여사 업체 에도 매 공업 용 고무 가지 고 합성 고무 도매  \n",
       "3                  영업 점 일 반 소비자 열쇠 잠금장치  \n",
       "4             어린이집 보호자 위탁 받아 취학 전 아동 보육  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('최종 전처리.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe6a41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>digit_1</th>\n",
       "      <th>digit_2</th>\n",
       "      <th>digit_3</th>\n",
       "      <th>Full Text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>95.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>카센터에서 자동차부분정비 타이어오일교환</td>\n",
       "      <td>카 센터 자동차 부분 정비 타이어 오일 교환</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G</td>\n",
       "      <td>47.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>상점내에서 일반인을 대상으로 채소 과일판매</td>\n",
       "      <td>상점 내 일반인 대상 채소 과일 판매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G</td>\n",
       "      <td>46.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>절단하여사업체에도매 공업용고무를가지고 합성고무도매</td>\n",
       "      <td>절단 하여사 업체 에도 매 공업 용 고무 가지 고 합성 고무 도매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G</td>\n",
       "      <td>47.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>영업점에서 일반소비자에게 열쇠잠금장치</td>\n",
       "      <td>영업 점 일 반 소비자 열쇠 잠금장치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q</td>\n",
       "      <td>87.0</td>\n",
       "      <td>872.0</td>\n",
       "      <td>어린이집 보호자의 위탁을 받아 취학전아동보육</td>\n",
       "      <td>어린이집 보호자 위탁 받아 취학 전 아동 보육</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  digit_1  digit_2  digit_3                    Full Text  \\\n",
       "0       S     95.0    952.0        카센터에서 자동차부분정비 타이어오일교환   \n",
       "1       G     47.0    472.0      상점내에서 일반인을 대상으로 채소 과일판매   \n",
       "2       G     46.0    467.0  절단하여사업체에도매 공업용고무를가지고 합성고무도매   \n",
       "3       G     47.0    475.0         영업점에서 일반소비자에게 열쇠잠금장치   \n",
       "4       Q     87.0    872.0     어린이집 보호자의 위탁을 받아 취학전아동보육   \n",
       "\n",
       "                             clean_text  \n",
       "0              카 센터 자동차 부분 정비 타이어 오일 교환  \n",
       "1                  상점 내 일반인 대상 채소 과일 판매  \n",
       "2  절단 하여사 업체 에도 매 공업 용 고무 가지 고 합성 고무 도매  \n",
       "3                  영업 점 일 반 소비자 열쇠 잠금장치  \n",
       "4             어린이집 보호자 위탁 받아 취학 전 아동 보육  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df[:1000000]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72d9965b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder1 = LabelEncoder()\n",
    "train['digit_1'] = encoder1.fit_transform(train['digit_1'])\n",
    "train['digit_1'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a3a3926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder2 = LabelEncoder()\n",
    "train['digit_2'] = encoder2.fit_transform(train['digit_2'])\n",
    "train['digit_2'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "937cd66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder3 = LabelEncoder()\n",
    "train['digit_3'] = encoder3.fit_transform(train['digit_3'])\n",
    "train['digit_3'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a4de6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = np.load('text.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c962a885",
   "metadata": {},
   "source": [
    "# 전처리 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e327888a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  633, 1943, 3832],\n",
       "       [   0,    0,    0, ...,  296,  147,   12],\n",
       "       [   0,    0,    0, ..., 1304,  608,   23],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 1444, 1030,   12],\n",
       "       [   0,    0,    0, ..., 1434, 1725,   49],\n",
       "       [   0,    0,    0, ...,   44, 1310,  203]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 21\n",
    "\n",
    "text = tf.keras.preprocessing.sequence.pad_sequences(text, maxlen=max_len)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0863303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = text[:1000000]\n",
    "test_data = text[1000000:]\n",
    "target = train['digit_1']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, target, test_size=0.2, shuffle=True, stratify=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8393f5a4",
   "metadata": {},
   "source": [
    "### Bidirectional - LSTM (digit1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18cd2472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM,Bidirectional,GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e5169ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10760\n",
    "embedding_dim = 128\n",
    "hidden_units = 128\n",
    "num_classes = 19 # 대분류 19개 카테고리\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(Bidirectional(LSTM(hidden_units, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(hidden_units)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(hidden_units, activation='tanh'))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0788822",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode = \"auto\", verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model1.h5', monitor='val_loss', mode = \"auto\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0945d920",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 2199s 110ms/step - loss: 0.1543 - accuracy: 0.9580 - val_loss: 0.1048 - val_accuracy: 0.9708\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10475, saving model to best_model1.h5\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 2259s 113ms/step - loss: 0.0941 - accuracy: 0.9737 - val_loss: 0.0936 - val_accuracy: 0.9735\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10475 to 0.09364, saving model to best_model1.h5\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 2340s 117ms/step - loss: 0.0793 - accuracy: 0.9778 - val_loss: 0.0931 - val_accuracy: 0.9740\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.09364 to 0.09313, saving model to best_model1.h5\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 2371s 119ms/step - loss: 0.0682 - accuracy: 0.9804 - val_loss: 0.0939 - val_accuracy: 0.9743\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09313\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 2428s 121ms/step - loss: 0.0594 - accuracy: 0.9829 - val_loss: 0.0961 - val_accuracy: 0.9743\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.09313\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=5, callbacks=[es, mc], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48f25875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 [==============================] - 252s 40ms/step - loss: 0.0979 - accuracy: 0.9739\n",
      "테스트 정확도: 0.9739\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8702188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.1877358e-06, 8.4878636e-08, 1.6217272e-06, ..., 1.1509170e-04,\n",
       "        2.0777001e-05, 5.3187392e-05],\n",
       "       [2.0993060e-05, 1.0097981e-05, 9.3919371e-06, ..., 4.0944320e-05,\n",
       "        7.2567753e-05, 6.6762143e-03],\n",
       "       [3.7637064e-06, 2.9767534e-07, 2.6332580e-03, ..., 3.1503259e-06,\n",
       "        1.0072624e-05, 1.0060821e-04],\n",
       "       ...,\n",
       "       [2.9552095e-05, 1.8878640e-06, 6.1975163e-04, ..., 1.0876021e-04,\n",
       "        1.7698061e-04, 3.7307595e-04],\n",
       "       [8.4484651e-07, 1.1765148e-06, 1.5032321e-03, ..., 2.5571619e-06,\n",
       "        6.5585191e-06, 1.8651126e-04],\n",
       "       [1.5346949e-07, 5.9876740e-08, 7.9369964e-04, ..., 2.9972682e-07,\n",
       "        3.1281827e-06, 2.7468255e-05]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1 = model.predict(X_test)\n",
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b95612d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 11,  6, ...,  8,  6,  6], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict1 = []\n",
    "for i in range(pred1.shape[0]):\n",
    "    predict1.append(pred1[i].argmax())\n",
    "predict1 = np.array(predict1)\n",
    "predict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42cef86c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       213\n",
      "           1       0.94      0.74      0.83        85\n",
      "           2       0.96      0.96      0.96     21038\n",
      "           3       0.97      0.86      0.91       151\n",
      "           4       0.84      0.86      0.85       451\n",
      "           5       0.94      0.95      0.94      7010\n",
      "           6       0.98      0.98      0.98     49294\n",
      "           7       1.00      0.99      0.99     19608\n",
      "           8       0.99      0.99      0.99     37485\n",
      "           9       0.94      0.92      0.93      2172\n",
      "          10       0.98      0.99      0.98      2076\n",
      "          11       0.98      0.98      0.98      8028\n",
      "          12       0.94      0.94      0.94      5687\n",
      "          13       0.87      0.90      0.88      3540\n",
      "          14       0.93      0.93      0.93       593\n",
      "          15       0.96      0.98      0.97      9322\n",
      "          16       0.98      0.97      0.97      7218\n",
      "          17       0.95      0.96      0.96      5950\n",
      "          18       0.98      0.97      0.98     20079\n",
      "\n",
      "    accuracy                           0.97    200000\n",
      "   macro avg       0.94      0.93      0.93    200000\n",
      "weighted avg       0.97      0.97      0.97    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ('Here is the classification report:')\n",
    "print (classification_report(y_test, predict1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ae65f4",
   "metadata": {},
   "source": [
    "### 모델개발용 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d318894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.24906444e-06, 2.70694525e-08, 1.70390165e-04, ...,\n",
       "        1.18408852e-05, 6.79882487e-06, 7.30940747e-06],\n",
       "       [5.86889655e-07, 8.53980453e-07, 1.41269830e-03, ...,\n",
       "        3.63686979e-07, 4.15976820e-06, 2.27669407e-05],\n",
       "       [2.39920723e-06, 4.04215371e-07, 3.74364354e-05, ...,\n",
       "        1.21279256e-04, 1.45669794e-03, 9.97923374e-01],\n",
       "       ...,\n",
       "       [1.06746527e-04, 9.11065513e-07, 6.14050718e-04, ...,\n",
       "        6.51831488e-06, 8.33224694e-05, 4.89315789e-05],\n",
       "       [1.60639356e-05, 1.18197795e-06, 1.66292721e-05, ...,\n",
       "        2.14294778e-05, 9.97276962e-01, 1.20382691e-04],\n",
       "       [1.06915322e-05, 7.36309175e-07, 2.75153634e-05, ...,\n",
       "        8.53607253e-06, 3.38268874e-05, 4.23385529e-04]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit1_pred = model.predict(test_data)\n",
    "digit1_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07fe8cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  6, 18, ...,  6, 17, 11], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit1_predict = []\n",
    "for i in range(digit1_pred.shape[0]):\n",
    "    digit1_predict.append(digit1_pred[i].argmax())\n",
    "digit1_predict = np.array(digit1_predict)\n",
    "digit1_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b88cf75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I', 'G', 'S', ..., 'G', 'R', 'L'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit1_predict = encoder1.inverse_transform(digit1_predict)\n",
    "digit1_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bdcbdfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digit1_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce5dabf",
   "metadata": {},
   "source": [
    "### Bidirectional - LSTM (digit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3cd5161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target2 = train['digit_2']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, target2, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b9f02f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10760\n",
    "embedding_dim = 128\n",
    "hidden_units = 128\n",
    "num_classes = 74 \n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(vocab_size, embedding_dim))\n",
    "model2.add(Bidirectional(LSTM(hidden_units, return_sequences=True)))\n",
    "model2.add(Bidirectional(LSTM(hidden_units)))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(hidden_units, activation='tanh'))\n",
    "model2.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0d4da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc2 = ModelCheckpoint('best_model2.h5', monitor='val_loss', mode = \"auto\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e4aaed3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 2743s 137ms/step - loss: 0.3662 - accuracy: 0.9031 - val_loss: 0.2445 - val_accuracy: 0.9332\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24453, saving model to best_model1.h5\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 2471s 124ms/step - loss: 0.2269 - accuracy: 0.9373 - val_loss: 0.2184 - val_accuracy: 0.9391\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.24453 to 0.21838, saving model to best_model1.h5\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 2822s 141ms/step - loss: 0.1956 - accuracy: 0.9446 - val_loss: 0.2142 - val_accuracy: 0.9397\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21838 to 0.21424, saving model to best_model1.h5\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 2377s 119ms/step - loss: 0.1750 - accuracy: 0.9497 - val_loss: 0.2133 - val_accuracy: 0.9415\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.21424 to 0.21331, saving model to best_model1.h5\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 3241s 162ms/step - loss: 0.1576 - accuracy: 0.9539 - val_loss: 0.2204 - val_accuracy: 0.9406\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.21331\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history2 = model2.fit(X_train, y_train, batch_size=32, epochs=5, callbacks=[es, mc2], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd7cba81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 [==============================] - 279s 44ms/step - loss: 0.2173 - accuracy: 0.9412\n",
      "테스트 정확도: 0.9412\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 정확도: %.4f\" % (model2.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8709b266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.8914500e-07, 1.6674186e-07, 1.2438110e-07, ..., 7.6858465e-05,\n",
       "        1.4080516e-06, 1.3811493e-04],\n",
       "       [3.4404434e-06, 5.1579121e-07, 2.1519449e-07, ..., 2.6983022e-05,\n",
       "        8.4983090e-05, 6.3103707e-06],\n",
       "       [3.2960767e-07, 3.7960756e-06, 1.3680912e-09, ..., 1.0017654e-06,\n",
       "        9.3332266e-05, 1.2250978e-06],\n",
       "       ...,\n",
       "       [3.0018998e-06, 2.5148944e-08, 1.6724691e-07, ..., 9.9977249e-01,\n",
       "        3.8668549e-07, 2.4822093e-05],\n",
       "       [5.2099719e-10, 1.8329423e-08, 2.9562949e-11, ..., 3.0474068e-06,\n",
       "        5.5468852e-10, 1.2819409e-07],\n",
       "       [4.0422859e-07, 1.6686792e-07, 5.6620333e-08, ..., 1.6117730e-07,\n",
       "        6.1884562e-06, 1.9596766e-06]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model2.predict(X_test)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "099e6ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([70, 24, 29, ..., 71, 57, 41], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict2 = []\n",
    "for i in range(pred2.shape[0]):\n",
    "    predict2.append(pred2[i].argmax())\n",
    "predict2 = np.array(predict2)\n",
    "predict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40b4a2f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.61      0.70       173\n",
      "           1       0.95      0.72      0.82        25\n",
      "           2       0.77      0.68      0.72        25\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.90      0.84      0.87        88\n",
      "           7       0.91      0.91      0.91      2893\n",
      "           8       0.78      0.70      0.74        90\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.88      0.79      0.83      1023\n",
      "          11       0.94      0.84      0.89      1068\n",
      "          12       0.87      0.78      0.82       287\n",
      "          13       0.81      0.67      0.73       383\n",
      "          14       0.81      0.80      0.81       348\n",
      "          15       0.87      0.91      0.89       840\n",
      "          16       0.54      0.37      0.44        19\n",
      "          17       0.72      0.66      0.69       591\n",
      "          18       0.52      0.22      0.31        63\n",
      "          19       0.72      0.79      0.75      1169\n",
      "          20       0.83      0.75      0.79       551\n",
      "          21       0.57      0.48      0.52       437\n",
      "          22       0.77      0.73      0.75      3378\n",
      "          23       0.75      0.60      0.67       632\n",
      "          24       0.72      0.63      0.67       605\n",
      "          25       0.66      0.74      0.70      1123\n",
      "          26       0.62      0.75      0.68      2455\n",
      "          27       0.58      0.44      0.50       497\n",
      "          28       0.82      0.45      0.58       220\n",
      "          29       0.89      0.78      0.83       645\n",
      "          30       0.72      0.75      0.74       925\n",
      "          31       0.82      0.88      0.85       656\n",
      "          32       0.94      0.89      0.91       147\n",
      "          33       0.79      0.90      0.84        21\n",
      "          34       0.86      0.86      0.86        97\n",
      "          35       0.95      0.77      0.85       351\n",
      "          36       1.00      0.50      0.67         6\n",
      "          37       0.84      0.83      0.83      1380\n",
      "          38       0.90      0.93      0.92      5605\n",
      "          39       0.95      0.94      0.95      1486\n",
      "          40       0.92      0.93      0.92     15454\n",
      "          41       0.96      0.96      0.96     32340\n",
      "          42       0.99      1.00      0.99     18243\n",
      "          43       0.84      0.82      0.83        56\n",
      "          44       1.00      0.45      0.62        11\n",
      "          45       0.94      0.92      0.93      1459\n",
      "          46       1.00      0.99      0.99      2822\n",
      "          47       0.99      0.99      0.99     34600\n",
      "          48       0.82      0.94      0.88      1067\n",
      "          49       0.86      0.86      0.86       298\n",
      "          50       0.88      0.78      0.82        36\n",
      "          51       0.94      0.88      0.91       249\n",
      "          52       0.93      0.56      0.70       381\n",
      "          53       0.80      0.62      0.70       157\n",
      "          54       0.96      0.94      0.95      1019\n",
      "          55       0.91      0.87      0.89       377\n",
      "          56       0.85      0.89      0.87       684\n",
      "          57       0.98      0.99      0.98      8115\n",
      "          58       0.79      0.82      0.81       388\n",
      "          59       0.90      0.95      0.92      2676\n",
      "          60       0.93      0.93      0.93      1359\n",
      "          61       0.94      0.85      0.89      1110\n",
      "          62       0.86      0.86      0.86       578\n",
      "          63       0.91      0.86      0.88      2012\n",
      "          64       0.91      0.88      0.89       895\n",
      "          65       0.88      0.93      0.90       574\n",
      "          66       0.96      0.98      0.97      9320\n",
      "          67       0.98      0.98      0.98      3597\n",
      "          68       0.97      0.95      0.96      3647\n",
      "          69       0.92      0.88      0.90       930\n",
      "          70       0.96      0.97      0.96      5058\n",
      "          71       0.96      0.96      0.96      4787\n",
      "          72       0.96      0.96      0.96      4072\n",
      "          73       0.99      0.99      0.99     11322\n",
      "\n",
      "    accuracy                           0.94    200000\n",
      "   macro avg       0.84      0.78      0.80    200000\n",
      "weighted avg       0.94      0.94      0.94    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ('Here is the classification report:')\n",
    "print (classification_report(y_test, predict2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81f277a",
   "metadata": {},
   "source": [
    "### 모델개발용 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f2da332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.1989308e-09, 1.4497396e-08, 3.0837860e-08, ..., 5.2259033e-08,\n",
       "        4.2988749e-08, 6.8238796e-07],\n",
       "       [4.8637266e-05, 8.7785349e-07, 8.7951355e-07, ..., 9.8136203e-05,\n",
       "        4.1451171e-04, 8.1442113e-06],\n",
       "       [2.0434825e-05, 5.2360431e-08, 6.9749564e-07, ..., 9.9898499e-01,\n",
       "        5.2941255e-07, 3.8075395e-05],\n",
       "       ...,\n",
       "       [1.2916678e-06, 7.9112351e-07, 1.2844343e-07, ..., 5.0421213e-06,\n",
       "        9.7873353e-06, 1.2135895e-05],\n",
       "       [1.3988320e-07, 1.9368488e-06, 3.7168946e-09, ..., 2.1473532e-05,\n",
       "        1.0832193e-07, 7.4764524e-05],\n",
       "       [5.2166695e-07, 2.1029943e-07, 1.1458310e-09, ..., 4.9704329e-05,\n",
       "        8.3851614e-07, 4.5041388e-06]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit2_pred = model2.predict(test_data)\n",
    "digit2_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4351a6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47, 40, 71, ..., 41, 69, 57], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit2_predict = []\n",
    "for i in range(digit2_pred.shape[0]):\n",
    "    digit2_predict.append(digit2_pred[i].argmax())\n",
    "digit2_predict = np.array(digit2_predict)\n",
    "digit2_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "83ae0716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56., 46., 94., ..., 47., 90., 68.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit2_predict = encoder2.inverse_transform(digit2_predict)\n",
    "digit2_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea745d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digit2_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d634a85",
   "metadata": {},
   "source": [
    "### Bidirectional - LSTM (digit3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29b6cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "target3 = train['digit_3']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, target3, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c491ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10760\n",
    "embedding_dim = 128\n",
    "hidden_units = 128\n",
    "num_classes = 225\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(vocab_size, embedding_dim))\n",
    "model3.add(Bidirectional(LSTM(hidden_units, return_sequences=True)))\n",
    "model3.add(Bidirectional(LSTM(hidden_units)))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(hidden_units, activation='tanh'))\n",
    "model3.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a30e36e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc3 = ModelCheckpoint('best_model3.h5', monitor='val_loss', mode = \"auto\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d1a8d60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 2405s 120ms/step - loss: 0.6577 - accuracy: 0.8395 - val_loss: 0.4063 - val_accuracy: 0.8952\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.40633, saving model to best_model3.h5\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 2508s 125ms/step - loss: 0.3718 - accuracy: 0.9032 - val_loss: 0.3559 - val_accuracy: 0.9077\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.40633 to 0.35587, saving model to best_model3.h5\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 2436s 122ms/step - loss: 0.3209 - accuracy: 0.9146 - val_loss: 0.3436 - val_accuracy: 0.9102\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.35587 to 0.34364, saving model to best_model3.h5\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 2233s 112ms/step - loss: 0.2886 - accuracy: 0.9221 - val_loss: 0.3426 - val_accuracy: 0.9122\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.34364 to 0.34259, saving model to best_model3.h5\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 2098s 105ms/step - loss: 0.2646 - accuracy: 0.9275 - val_loss: 0.3407 - val_accuracy: 0.9133\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.34259 to 0.34070, saving model to best_model3.h5\n"
     ]
    }
   ],
   "source": [
    "model3.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history3 = model3.fit(X_train, y_train, batch_size=32, epochs=5, callbacks=[es, mc3], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da5a068d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 [==============================] - 158s 25ms/step - loss: 0.3473 - accuracy: 0.9118\n",
      "테스트 정확도: 0.9118\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 정확도: %.4f\" % (model3.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e079f63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.9504253e-07, 2.9637954e-07, 1.5003279e-07, ..., 7.9812999e-08,\n",
       "        2.8413565e-08, 5.1654251e-08],\n",
       "       [1.9241886e-06, 2.5428091e-07, 6.3702167e-08, ..., 2.8238164e-06,\n",
       "        1.2378317e-06, 3.4912918e-07],\n",
       "       [2.2280405e-10, 5.8984290e-11, 8.4589186e-10, ..., 9.7125906e-08,\n",
       "        1.2082144e-07, 3.7002297e-07],\n",
       "       ...,\n",
       "       [6.0838302e-06, 4.1361324e-07, 2.7208223e-05, ..., 3.0871908e-07,\n",
       "        7.8518035e-08, 4.3670065e-05],\n",
       "       [4.9525781e-05, 2.9938876e-06, 7.0327784e-05, ..., 2.8361457e-08,\n",
       "        2.4947444e-06, 9.6627969e-07],\n",
       "       [3.8094641e-10, 2.0471983e-08, 4.6213361e-10, ..., 3.2652761e-10,\n",
       "        2.4746083e-07, 3.8060600e-07]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model3.predict(X_test)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1077f699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([126, 159, 212, ..., 119,  18, 147], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict3 = []\n",
    "for i in range(pred3.shape[0]):\n",
    "    predict3.append(pred3[i].argmax())\n",
    "predict3 = np.array(predict3)\n",
    "predict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85acfef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.78        75\n",
      "           1       0.92      0.79      0.85        56\n",
      "           2       0.34      0.53      0.41        36\n",
      "           3       0.76      0.73      0.74        22\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.86      0.67      0.75        18\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.81      0.50      0.62        42\n",
      "          10       0.95      0.91      0.93        45\n",
      "          12       0.70      0.80      0.75       148\n",
      "          13       0.71      0.86      0.78       182\n",
      "          14       0.75      0.66      0.70       229\n",
      "          15       0.92      0.92      0.92       147\n",
      "          16       1.00      0.21      0.35        19\n",
      "          17       0.81      0.78      0.79       274\n",
      "          18       0.89      0.88      0.89      1892\n",
      "          19       0.91      0.65      0.76        63\n",
      "          20       0.78      0.80      0.79        54\n",
      "          21       0.13      0.06      0.08        34\n",
      "          23       0.69      0.70      0.70        93\n",
      "          24       0.80      0.75      0.77       562\n",
      "          25       0.79      0.56      0.66        48\n",
      "          26       0.66      0.78      0.71       188\n",
      "          27       0.64      0.56      0.59       168\n",
      "          28       0.89      0.90      0.90       900\n",
      "          29       0.67      0.77      0.71        13\n",
      "          30       0.85      0.80      0.83        51\n",
      "          31       0.81      0.70      0.75       119\n",
      "          32       0.85      0.65      0.74       169\n",
      "          33       0.73      0.81      0.77       105\n",
      "          34       0.72      0.60      0.65        85\n",
      "          35       0.63      0.65      0.64       256\n",
      "          36       1.00      0.10      0.18        10\n",
      "          37       0.24      0.26      0.25        39\n",
      "          38       0.78      0.82      0.80       187\n",
      "          39       0.66      0.39      0.49       108\n",
      "          40       0.89      0.90      0.90       819\n",
      "          41       0.67      0.25      0.36         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.33      0.55      0.41        11\n",
      "          44       0.41      0.34      0.37        76\n",
      "          45       0.45      0.58      0.51       129\n",
      "          46       0.68      0.69      0.68        64\n",
      "          47       0.65      0.67      0.66       342\n",
      "          48       0.00      0.00      0.00         8\n",
      "          49       0.00      0.00      0.00         9\n",
      "          50       0.39      0.52      0.44        33\n",
      "          51       0.20      0.04      0.06        28\n",
      "          52       0.68      0.71      0.69       151\n",
      "          53       0.67      0.77      0.72       978\n",
      "          54       0.76      0.62      0.68       102\n",
      "          55       0.75      0.73      0.74       143\n",
      "          56       0.88      0.80      0.83       161\n",
      "          57       0.58      0.81      0.68       166\n",
      "          58       0.63      0.28      0.38       247\n",
      "          59       0.30      0.37      0.33       111\n",
      "          60       0.60      0.50      0.55        78\n",
      "          61       0.78      0.65      0.71       852\n",
      "          62       0.00      0.00      0.00         8\n",
      "          63       0.64      0.75      0.69      2596\n",
      "          64       0.46      0.24      0.31        68\n",
      "          65       0.67      0.58      0.62       364\n",
      "          66       0.35      0.43      0.39        49\n",
      "          67       0.48      0.57      0.52       156\n",
      "          68       0.68      0.25      0.37        51\n",
      "          69       0.00      0.00      0.00         3\n",
      "          70       0.80      0.74      0.77       283\n",
      "          71       0.49      0.54      0.51       287\n",
      "          72       0.72      0.53      0.61        34\n",
      "          73       0.78      0.78      0.78         9\n",
      "          74       0.70      0.70      0.70       571\n",
      "          75       1.00      0.04      0.08        24\n",
      "          76       0.63      0.67      0.65        92\n",
      "          77       0.81      0.63      0.71       243\n",
      "          78       0.56      0.36      0.44       119\n",
      "          79       0.39      0.21      0.27        68\n",
      "          80       0.60      0.62      0.61       996\n",
      "          81       0.66      0.64      0.65      1457\n",
      "          82       0.00      0.00      0.00         3\n",
      "          83       0.61      0.53      0.57        79\n",
      "          84       0.45      0.37      0.41       487\n",
      "          85       0.00      0.00      0.00         5\n",
      "          86       0.69      0.62      0.65       158\n",
      "          87       0.54      0.32      0.40        22\n",
      "          88       0.62      0.23      0.33        22\n",
      "          89       0.43      0.24      0.31        25\n",
      "          90       0.84      0.80      0.82       652\n",
      "          91       0.88      0.68      0.77       119\n",
      "          92       0.50      0.07      0.12        14\n",
      "          93       0.63      0.44      0.52        61\n",
      "          94       0.71      0.53      0.61        45\n",
      "          95       0.71      0.77      0.74       676\n",
      "          96       0.88      0.84      0.86       676\n",
      "          97       0.88      0.96      0.92       137\n",
      "          98       0.67      0.73      0.70        22\n",
      "          99       1.00      0.29      0.44         7\n",
      "         100       1.00      0.76      0.86        29\n",
      "         101       0.74      0.92      0.82        75\n",
      "         102       0.83      0.84      0.84       151\n",
      "         103       0.70      0.65      0.67        79\n",
      "         104       0.68      0.63      0.65       122\n",
      "         105       0.75      0.75      0.75         4\n",
      "         106       0.86      0.87      0.86       682\n",
      "         107       0.78      0.62      0.69       698\n",
      "         108       0.81      0.81      0.81      1002\n",
      "         109       0.83      0.87      0.85      1169\n",
      "         110       0.93      0.90      0.91       839\n",
      "         111       0.90      0.92      0.91      2286\n",
      "         112       0.63      0.51      0.56       122\n",
      "         113       0.86      0.79      0.82       344\n",
      "         114       0.98      0.96      0.97       484\n",
      "         115       0.88      0.94      0.91       871\n",
      "         116       0.88      0.83      0.86        78\n",
      "         117       0.76      0.77      0.76       427\n",
      "         118       0.80      0.81      0.80       569\n",
      "         119       0.89      0.91      0.90      3591\n",
      "         120       0.84      0.79      0.82      3703\n",
      "         121       0.83      0.87      0.85      2940\n",
      "         122       0.87      0.82      0.85      1631\n",
      "         123       0.84      0.87      0.85      2386\n",
      "         124       0.61      0.64      0.62       137\n",
      "         125       0.95      0.95      0.95      5236\n",
      "         126       0.89      0.89      0.89      5132\n",
      "         127       0.91      0.92      0.91      1858\n",
      "         128       0.93      0.97      0.95      7215\n",
      "         129       0.84      0.88      0.86      2617\n",
      "         130       0.89      0.85      0.87      1399\n",
      "         131       0.98      0.97      0.97       952\n",
      "         132       0.93      0.92      0.92      6050\n",
      "         133       0.90      0.91      0.90      1887\n",
      "         134       0.80      0.92      0.86        13\n",
      "         135       1.00      1.00      1.00      7984\n",
      "         136       0.99      0.99      0.99      9938\n",
      "         137       0.92      0.95      0.94       409\n",
      "         138       0.00      0.00      0.00         1\n",
      "         139       0.88      0.80      0.84        65\n",
      "         140       0.00      0.00      0.00         4\n",
      "         141       1.00      0.40      0.57         5\n",
      "         143       0.90      0.89      0.90       333\n",
      "         144       0.91      0.91      0.91      1158\n",
      "         145       0.98      0.99      0.99      2528\n",
      "         146       0.97      0.89      0.93       260\n",
      "         147       0.98      0.98      0.98     24534\n",
      "         148       0.97      0.97      0.97     10112\n",
      "         149       0.86      0.88      0.87       287\n",
      "         150       0.85      0.94      0.89       773\n",
      "         151       0.90      0.71      0.79       258\n",
      "         152       0.78      0.67      0.72        42\n",
      "         153       0.67      0.67      0.67         6\n",
      "         154       0.65      0.74      0.69        47\n",
      "         155       0.97      0.96      0.97       162\n",
      "         156       0.41      0.86      0.56        63\n",
      "         157       0.84      0.55      0.66       383\n",
      "         158       0.68      0.52      0.59        91\n",
      "         159       0.60      0.71      0.65        82\n",
      "         160       0.98      0.98      0.98       841\n",
      "         161       0.82      0.45      0.58        40\n",
      "         162       0.89      0.75      0.82       210\n",
      "         163       0.82      0.94      0.88       327\n",
      "         165       1.00      0.47      0.64        34\n",
      "         166       0.76      0.85      0.80       241\n",
      "         167       0.97      0.83      0.90       371\n",
      "         168       0.89      0.95      0.92      1395\n",
      "         169       0.99      0.98      0.98      6593\n",
      "         170       0.82      0.80      0.81       275\n",
      "         171       0.71      0.28      0.40        78\n",
      "         172       0.97      0.96      0.97       827\n",
      "         173       0.98      0.99      0.99       606\n",
      "         174       0.85      0.85      0.85       581\n",
      "         175       0.76      0.89      0.82        18\n",
      "         176       0.89      0.81      0.85       685\n",
      "         177       0.42      0.65      0.51        20\n",
      "         178       0.92      0.89      0.91      1027\n",
      "         179       0.70      0.89      0.78       323\n",
      "         180       0.98      0.99      0.98       223\n",
      "         181       0.81      0.85      0.83       345\n",
      "         182       0.95      0.97      0.96       478\n",
      "         183       0.81      0.69      0.74       116\n",
      "         184       0.72      0.70      0.71       162\n",
      "         185       0.94      0.89      0.92       377\n",
      "         186       0.39      0.78      0.52        46\n",
      "         187       0.93      0.95      0.94       748\n",
      "         188       0.95      0.95      0.95       523\n",
      "         189       0.86      0.78      0.82       106\n",
      "         190       0.69      0.72      0.71       739\n",
      "         191       0.92      0.92      0.92       192\n",
      "         192       0.85      0.89      0.87       377\n",
      "         193       0.80      0.79      0.79       301\n",
      "         194       0.00      0.00      0.00         3\n",
      "         195       0.89      0.87      0.88       206\n",
      "         196       0.55      0.75      0.64        89\n",
      "         198       0.94      0.94      0.94       271\n",
      "         199       0.67      0.50      0.57         8\n",
      "         200       0.99      0.99      0.99       698\n",
      "         201       0.96      0.99      0.98       281\n",
      "         202       0.96      0.93      0.94        83\n",
      "         203       0.80      0.80      0.80        15\n",
      "         204       0.91      0.94      0.93      3336\n",
      "         205       0.90      0.90      0.90      4736\n",
      "         206       0.76      0.67      0.71       159\n",
      "         207       0.89      0.76      0.82       189\n",
      "         208       0.98      0.99      0.98      3032\n",
      "         209       1.00      0.96      0.98       162\n",
      "         210       0.68      0.76      0.72       234\n",
      "         211       0.92      0.87      0.90       443\n",
      "         212       0.95      0.93      0.94      3120\n",
      "         213       0.81      0.72      0.76       281\n",
      "         214       0.95      0.92      0.94       592\n",
      "         215       0.96      0.95      0.95      1970\n",
      "         216       0.96      0.98      0.97      3045\n",
      "         217       0.83      0.54      0.65       344\n",
      "         218       0.80      0.86      0.83        92\n",
      "         219       0.93      0.96      0.94      4360\n",
      "         220       0.91      0.92      0.91       297\n",
      "         221       0.97      0.99      0.98      2412\n",
      "         222       0.91      0.94      0.92      1294\n",
      "         223       0.99      0.99      0.99      8493\n",
      "         224       0.99      0.96      0.97      2580\n",
      "\n",
      "    accuracy                           0.91    200000\n",
      "   macro avg       0.74      0.69      0.70    200000\n",
      "weighted avg       0.91      0.91      0.91    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ('Here is the classification report:')\n",
    "print (classification_report(y_test, predict3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c974cebe",
   "metadata": {},
   "source": [
    "#### 모델개발용 데이터 예측 (digit_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa6d0143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.7048184e-09, 2.6058706e-07, 1.0722601e-08, ..., 4.5377151e-09,\n",
       "        4.1760060e-08, 3.7099915e-07],\n",
       "       [1.6224116e-09, 1.0008424e-08, 4.4535620e-09, ..., 6.9600619e-06,\n",
       "        2.9999883e-09, 9.7333280e-11],\n",
       "       [1.4325600e-10, 2.2990873e-10, 1.2305840e-11, ..., 7.9351048e-07,\n",
       "        8.5486533e-07, 8.4058996e-07],\n",
       "       ...,\n",
       "       [2.0446165e-05, 7.9516710e-08, 1.4600730e-06, ..., 3.4340376e-06,\n",
       "        1.6763615e-05, 5.0918852e-06],\n",
       "       [2.0826040e-07, 5.0908028e-08, 4.7005601e-06, ..., 3.7785099e-07,\n",
       "        3.0968982e-05, 3.6230758e-05],\n",
       "       [3.4283247e-09, 1.6284558e-08, 4.7453199e-08, ..., 1.3401958e-06,\n",
       "        3.1349387e-07, 8.3375307e-06]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit3_pred = model3.predict(test_data)\n",
    "digit3_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f223ad4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([147, 122, 219, ..., 132, 214, 169], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit3_predict = []\n",
    "for i in range(digit3_pred.shape[0]):\n",
    "    digit3_predict.append(digit3_pred[i].argmax())\n",
    "digit3_predict = np.array(digit3_predict)\n",
    "digit3_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a798fa0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([561., 466., 949., ..., 478., 902., 682.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit3_predict = encoder3.inverse_transform(digit3_predict)\n",
    "digit3_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1cff501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digit3_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4acd7f6",
   "metadata": {},
   "source": [
    "### 답안 작성용 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f252e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('문서분류/답안 작성용 파일.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6eddcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digit1_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781e4634",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(digit2_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5325b937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digit3_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8bae09a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['digit_1'] = digit1_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "22c68c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['digit_2'] = digit2_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87ebe4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['digit_3'] = digit3_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2da3dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('답안 작성용 파일.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
